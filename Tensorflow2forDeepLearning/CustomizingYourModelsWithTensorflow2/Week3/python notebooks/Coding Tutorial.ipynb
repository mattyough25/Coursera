{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modelling \n",
    "\n",
    "## Coding tutorials\n",
    " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
    " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
    " #### [3. The Embedding layer](#coding_tutorial_3)\n",
    " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
    " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
    " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## The IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import imdb\n",
    "import tensorflow.keras.datasets.imdb as imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and assign the data set using load_data()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the type of the data\n",
    "\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the data\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element input\n",
    "# Notice encoding\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element output\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset with different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with defaults\n",
    "#imdb.load_data(path='imdb.npz',index_from=3)\n",
    "\n",
    "# ~/.keras/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the vocabulary to the top 500 words using num_words\n",
    "\n",
    "#imdb.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the top 10 most frequent words using skip_top\n",
    "\n",
    "#imdb.load_data(skip_top=10, num_words=1000, oov_char=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the sequence lengths to 500 using maxlen\n",
    "\n",
    "#imdb.load_data(max_len=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use '1' as the character that indicates the start of a sequence\n",
    "\n",
    "#imdb.load_data(start_char=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb word index using get_word_index()\n",
    "\n",
    "imdb_word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the word index as a dictionary,\n",
    "# accounting for index_from.\n",
    "\n",
    "index_from = 3\n",
    "imdb_word_index = {key: value + index_from for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52256"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a specific word's index\n",
    "\n",
    "imdb_word_index['simpsonian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an input sentence\n",
    "\n",
    "imdb_word_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'film',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'casting',\n",
       " 'location',\n",
       " 'scenery',\n",
       " 'story',\n",
       " 'direction',\n",
       " \"everyone's\",\n",
       " 'really',\n",
       " 'suited',\n",
       " 'the',\n",
       " 'part',\n",
       " 'they',\n",
       " 'played',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'imagine',\n",
       " 'being',\n",
       " 'there',\n",
       " 'robert',\n",
       " \"redford's\",\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'same',\n",
       " 'being',\n",
       " 'director',\n",
       " \"norman's\",\n",
       " 'father',\n",
       " 'came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'same',\n",
       " 'scottish',\n",
       " 'island',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'so',\n",
       " 'i',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'real',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " 'the',\n",
       " 'witty',\n",
       " 'remarks',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'film',\n",
       " 'were',\n",
       " 'great',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'released',\n",
       " 'for',\n",
       " 'retail',\n",
       " 'and',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'it',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'fishing',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'really',\n",
       " 'cried',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'if',\n",
       " 'you',\n",
       " 'cry',\n",
       " 'at',\n",
       " 'a',\n",
       " 'film',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'good',\n",
       " 'and',\n",
       " 'this',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'also',\n",
       " 'congratulations',\n",
       " 'to',\n",
       " 'the',\n",
       " 'two',\n",
       " 'little',\n",
       " \"boy's\",\n",
       " 'that',\n",
       " 'played',\n",
       " 'the',\n",
       " \"part's\",\n",
       " 'of',\n",
       " 'norman',\n",
       " 'and',\n",
       " 'paul',\n",
       " 'they',\n",
       " 'were',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'children',\n",
       " 'are',\n",
       " 'often',\n",
       " 'left',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'praising',\n",
       " 'list',\n",
       " 'i',\n",
       " 'think',\n",
       " 'because',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'play',\n",
       " 'them',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " 'are',\n",
       " 'such',\n",
       " 'a',\n",
       " 'big',\n",
       " 'profile',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'but',\n",
       " 'these',\n",
       " 'children',\n",
       " 'are',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'praised',\n",
       " 'for',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'story',\n",
       " 'was',\n",
       " 'so',\n",
       " 'lovely',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'true',\n",
       " 'and',\n",
       " 'was',\n",
       " \"someone's\",\n",
       " 'life',\n",
       " 'after',\n",
       " 'all',\n",
       " 'that',\n",
       " 'was',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sentiment value\n",
    "\n",
    "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Padding and Masking Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb data set\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the input data shape\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the inputs to the maximum length using maxlen\n",
    "\n",
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding='post', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the output data shape\n",
    "\n",
    "padded_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking expects to see (batch, sequence, features)\n",
    "# Create a dummy feature dimension using expand_dims\n",
    "\n",
    "padded_x_train = np.expand_dims(padded_x_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Masking layer \n",
    "\n",
    "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
    "masking_layer = tf.keras.layers.Masking(mask_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass tf_x_train to it\n",
    "\n",
    "masked_x_train = masking_layer(tf_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25000, 300, 1), dtype=float32, numpy=\n",
       "array([[[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [2.200e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.940e+02],\n",
       "        [1.153e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [4.700e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.100e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.446e+03],\n",
       "        [7.079e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.700e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the dataset\n",
    "\n",
    "tf_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25000, 300, 1), dtype=float32, numpy=\n",
       "array([[[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [2.200e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.940e+02],\n",
       "        [1.153e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [4.700e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.100e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.446e+03],\n",
       "        [7.079e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.700e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25000, 300), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the ._keras_mask for the dataset\n",
    "\n",
    "masked_x_train._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer using layers.Embedding\n",
    "# Specify input_dim, output_dim, input_length\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
       "array([[[[ 0.04796429,  0.03189125, -0.00692123, -0.01982382,\n",
       "           0.01230433, -0.01432098, -0.0273539 , -0.03566893,\n",
       "          -0.03518577,  0.02058308, -0.00474087, -0.01169442,\n",
       "           0.00419116,  0.01125995,  0.00554067, -0.04753208]],\n",
       "\n",
       "        [[ 0.02926128,  0.03192237, -0.02111466, -0.02262906,\n",
       "           0.04346129,  0.03194186, -0.00015073, -0.03182178,\n",
       "          -0.00547377,  0.00958184, -0.04657329,  0.01677239,\n",
       "          -0.00181972,  0.03845377, -0.00787817, -0.01899423]],\n",
       "\n",
       "        [[ 0.03234303, -0.02127122,  0.02738797,  0.00555897,\n",
       "          -0.00124831,  0.04509136,  0.00387986,  0.01161321,\n",
       "           0.04771319,  0.04001459, -0.02694546, -0.01848445,\n",
       "          -0.01219078,  0.00950123,  0.00479709, -0.00965381]],\n",
       "\n",
       "        [[-0.02510841, -0.04593954,  0.01298102, -0.01337932,\n",
       "          -0.01464703, -0.04395757, -0.02932476, -0.03640841,\n",
       "          -0.03562222, -0.02801461,  0.04709226,  0.03206659,\n",
       "           0.01615104,  0.03626097, -0.02472185, -0.03714111]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an Embedding layer output for a fixed input\n",
    "# Expects an input of shape (batch, sequence, feature)\n",
    "\n",
    "sequence_of_indices = tf.constant([[[0], [1], [5], [500]]])\n",
    "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
    "sequence_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04796429,  0.03189125, -0.00692123, ...,  0.01125995,\n",
       "         0.00554067, -0.04753208],\n",
       "       [ 0.02926128,  0.03192237, -0.02111466, ...,  0.03845377,\n",
       "        -0.00787817, -0.01899423],\n",
       "       [-0.0257191 , -0.02480512,  0.04000496, ..., -0.0035895 ,\n",
       "         0.02478902,  0.02480343],\n",
       "       ...,\n",
       "       [ 0.04734952,  0.00378656,  0.02271506, ...,  0.0021296 ,\n",
       "        -0.03397387, -0.00464196],\n",
       "       [-0.04825158, -0.01676574, -0.04133451, ..., -0.00087372,\n",
       "         0.0492768 , -0.02871077],\n",
       "       [-0.02510841, -0.04593954,  0.01298102, ...,  0.03626097,\n",
       "        -0.02472185, -0.03714111]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Embedding layer weights using get_weights()\n",
    "\n",
    "embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03715342, -0.00394857,  0.00134257,  0.02474825, -0.0241991 ,\n",
       "       -0.04180843,  0.0309121 ,  0.01703861,  0.00905221, -0.01276096,\n",
       "        0.04972662,  0.01474421,  0.02858358, -0.00701248,  0.00834415,\n",
       "        0.04551356], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the 14th index\n",
    "\n",
    "embedding_layer.get_weights()[0][14,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layer that uses the mask_zero kwarg\n",
    "\n",
    "masking_embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16, mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 1), dtype=bool, numpy=\n",
       "array([[[False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this layer to the sequence and see the _keras_mask property\n",
    "\n",
    "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices)\n",
    "masked_sequence_of_embeddings._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the keys and values of the word index\n",
    "\n",
    "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'and',\n",
       " 'have',\n",
       " 'everything',\n",
       " 'that',\n",
       " \"he's\",\n",
       " 'made',\n",
       " 'on',\n",
       " 'dvd',\n",
       " 'except',\n",
       " 'for',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'the',\n",
       " '2',\n",
       " 'hour',\n",
       " 'twin',\n",
       " 'peaks',\n",
       " 'movie',\n",
       " 'so',\n",
       " 'when',\n",
       " 'i',\n",
       " 'found',\n",
       " 'out',\n",
       " 'about',\n",
       " 'this',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'grabbed',\n",
       " 'it',\n",
       " 'and',\n",
       " 'and',\n",
       " 'what',\n",
       " 'is',\n",
       " 'this',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'drawn',\n",
       " 'black',\n",
       " 'and',\n",
       " 'white',\n",
       " 'cartoons',\n",
       " 'that',\n",
       " 'are',\n",
       " 'loud',\n",
       " 'and',\n",
       " 'foul',\n",
       " 'mouthed',\n",
       " 'and',\n",
       " 'unfunny',\n",
       " 'maybe',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " \"what's\",\n",
       " 'good',\n",
       " 'but',\n",
       " 'maybe',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'crap',\n",
       " 'that',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'public',\n",
       " 'under',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'few',\n",
       " 'bucks',\n",
       " 'too',\n",
       " 'let',\n",
       " 'me',\n",
       " 'make',\n",
       " 'it',\n",
       " 'clear',\n",
       " 'that',\n",
       " 'i',\n",
       " \"didn't\",\n",
       " 'care',\n",
       " 'about',\n",
       " 'the',\n",
       " 'foul',\n",
       " 'language',\n",
       " 'part',\n",
       " 'but',\n",
       " 'had',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'because',\n",
       " 'my',\n",
       " 'neighbors',\n",
       " 'might',\n",
       " 'have',\n",
       " 'all',\n",
       " 'in',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'highly',\n",
       " 'disappointing',\n",
       " 'release',\n",
       " 'and',\n",
       " 'may',\n",
       " 'well',\n",
       " 'have',\n",
       " 'just',\n",
       " 'been',\n",
       " 'left',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'set',\n",
       " 'as',\n",
       " 'a',\n",
       " 'curiosity',\n",
       " 'i',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'you',\n",
       " \"don't\",\n",
       " 'spend',\n",
       " 'your',\n",
       " 'money',\n",
       " 'on',\n",
       " 'this',\n",
       " '2',\n",
       " 'out',\n",
       " 'of',\n",
       " '10']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first dataset example sentence\n",
    "\n",
    "[inv_imdb_word_index[index] for index in x_train[100] if index > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Embedding layer into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum token value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an embedding dimension\n",
    "\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using Sequential:\n",
    "#     1. Embedding layer\n",
    "#     2. GlobalAveragePooling1D\n",
    "#     3. Dense\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API refresher: use the Model to build the same model\n",
    "\n",
    "review_sequence = tf.keras.Input((None, ))\n",
    "embedding_sequence = tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim)(review_sequence)\n",
    "average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
    "\n",
    "model = tf.keras.Model(inputs=review_sequence, outputs=positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 16)          160016    \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a binary cross-entropy loss\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 5s 5ms/step - loss: 0.6900 - accuracy: 0.5496 - val_loss: 0.6855 - val_accuracy: 0.5047\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.6726 - accuracy: 0.6732 - val_loss: 0.6539 - val_accuracy: 0.6984\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.6336 - accuracy: 0.7489 - val_loss: 0.6076 - val_accuracy: 0.7594\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.5838 - accuracy: 0.7892 - val_loss: 0.5613 - val_accuracy: 0.7516\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.5356 - accuracy: 0.8135 - val_loss: 0.5193 - val_accuracy: 0.7922\n"
     ]
    }
   ],
   "source": [
    "# Train the model using .fit(), savng its history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test),validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The TensorFlow embedding projector\n",
    "\n",
    "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embedding layer's weights from the trained model\n",
    "\n",
    "weights = model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the word Embeddings to tsv files\n",
    "# Two files: \n",
    "#     one contains the embedding labels (meta.tsv),\n",
    "#     one contains the embeddings (vecs.tsv)\n",
    "\n",
    "import io\n",
    "from os import path\n",
    "\n",
    "out_v = io.open(path.join('embedding_data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
    "out_m = io.open(path.join('embedding_data', 'meta.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "k = 0\n",
    "\n",
    "for word, token in imdb_word_index.items():\n",
    "    if k != 0:\n",
    "        out_m.write('\\n')\n",
    "        out_v.write('\\n')\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
    "    out_m.write(word)\n",
    "    k += 1\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "# beware large collections of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Recurrent neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and pass an input to a SimpleRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleRNN layer and test it\n",
    "\n",
    "simplernn_layer = tf.keras.layers.SimpleRNN(units=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ 1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         1., -1., -1.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that only the final cell output is returned\n",
    "\n",
    "sequence = tf.constant([[[1., 1.], [2., 2.], [56., -100.]]])\n",
    "layer_output = simplernn_layer(sequence)\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build the model:\n",
    "# 1. Embedding.\n",
    "# 2. LSTM.\n",
    "# 3. Dense.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(units=16),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary cross-entropy loss\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "536/536 [==============================] - 31s 53ms/step - loss: 0.4459 - accuracy: 0.7935\n",
      "Epoch 2/3\n",
      "536/536 [==============================] - 34s 63ms/step - loss: 0.2346 - accuracy: 0.9116\n",
      "Epoch 3/3\n",
      "536/536 [==============================] - 42s 78ms/step - loss: 0.1707 - accuracy: 0.9403\n"
     ]
    }
   ],
   "source": [
    "# Fit the model and save its training history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\nplt.style.use('ggplot')\\n\\nhistory_dict = history.history\\n\\nacc      = history_dict['accuracy']\\nval_acc  = history_dict['val_accuracy']\\nloss     = history_dict['loss']\\nval_loss = history_dict['val_loss']\\n\\nepochs = range(1, len(acc) + 1)\\n\\nplt.figure(figsize=(14,5))\\nplt.plot(epochs, acc, marker='.', label='Training acc')\\nplt.plot(epochs, val_acc, marker='.', label='Validation acc')\\nplt.title('Training and validation accuracy')\\nplt.xlabel('Epoch')\\nplt.ylabel('Classification accuracy')\\nplt.legend(loc='lower right')\\nplt.ylim(0, 1);\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['please',\n",
       " 'give',\n",
       " 'this',\n",
       " 'one',\n",
       " 'a',\n",
       " 'miss',\n",
       " 'br',\n",
       " 'br',\n",
       " 'and',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cast',\n",
       " 'rendered',\n",
       " 'terrible',\n",
       " 'performances',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'flat',\n",
       " 'flat',\n",
       " 'flat',\n",
       " 'br',\n",
       " 'br',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'how',\n",
       " 'michael',\n",
       " 'madison',\n",
       " 'could',\n",
       " 'have',\n",
       " 'allowed',\n",
       " 'this',\n",
       " 'one',\n",
       " 'on',\n",
       " 'his',\n",
       " 'plate',\n",
       " 'he',\n",
       " 'almost',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'know',\n",
       " 'this',\n",
       " \"wasn't\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'work',\n",
       " 'out',\n",
       " 'and',\n",
       " 'his',\n",
       " 'performance',\n",
       " 'was',\n",
       " 'quite',\n",
       " 'so',\n",
       " 'all',\n",
       " 'you',\n",
       " 'madison',\n",
       " 'fans',\n",
       " 'give',\n",
       " 'this',\n",
       " 'a',\n",
       " 'miss']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first test data example sentence\n",
    "# (invert the word index)\n",
    "\n",
    "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_test[0] if index > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 845ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01510755]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model prediction using model.predict()\n",
    "\n",
    "model.predict(x_test[None, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the corresponding label\n",
    "\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_6\"></a>\n",
    "## Stacked RNNs and the Bidirectional wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words=5000,maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build stacked and bidirectional recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value and specify an embedding dimension\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(units=32, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(units=32, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8), merge_mode='sum', backward_layer=tf.keras.layers.GRU(units=8, go_backwards=True)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8, return_sequences=True), merge_mode='concat'),\n",
    "    tf.keras.layers.GRU(units=8, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "536/536 [==============================] - 112s 199ms/step - loss: 0.4124 - accuracy: 0.8045\n",
      "Epoch 2/3\n",
      "536/536 [==============================] - 100s 186ms/step - loss: 0.2449 - accuracy: 0.9084\n",
      "Epoch 3/3\n",
      "536/536 [==============================] - 96s 179ms/step - loss: 0.1845 - accuracy: 0.9358\n"
     ]
    }
   ],
   "source": [
    "# Train the model, saving its history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
